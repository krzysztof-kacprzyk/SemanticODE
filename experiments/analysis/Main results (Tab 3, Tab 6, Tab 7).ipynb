{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../results/Main/summary.csv')\n",
    "\n",
    "# data = data.iloc[-21:,:]\n",
    "total_elapsed_time = data['time_elapsed'].sum()\n",
    "\n",
    "data = data[['method','test_loss_mean','test_loss_std','dataset_name']]\n",
    "\n",
    "# Extract noise ratio from dataset name\n",
    "def extract_noise_ratio(dataset_name):\n",
    "    parts = dataset_name.split('_')\n",
    "    for part in parts:\n",
    "        if 'noise' in part:\n",
    "            return float(part.split('=')[1])\n",
    "    return 0.01\n",
    "        \n",
    "def extract_core_dataset_name(dataset_name):\n",
    "    parts = dataset_name.split('_')\n",
    "    return parts[0]\n",
    "\n",
    "def dataframe_to_markdown(df):\n",
    "    # Get the column headers\n",
    "    headers = df.columns.tolist()\n",
    "    \n",
    "    # Create the header row\n",
    "    header_row = '| | ' + ' | '.join(headers) + ' |'\n",
    "    \n",
    "    # Create the separator row\n",
    "    separator_row = '| --- | ' + ' | '.join(['---'] * len(headers)) + ' |'\n",
    "    \n",
    "    # Create the data rows\n",
    "    data_rows = []\n",
    "    for index, row in df.iterrows():\n",
    "        data_row = '| ' + index + ' | ' + ' | '.join(str(cell).strip() for cell in row) + ' |'\n",
    "        data_rows.append(data_row)\n",
    "    \n",
    "    # Combine all rows into a single markdown table string\n",
    "    markdown_table = '\\n'.join([header_row, separator_row] + data_rows)\n",
    "    \n",
    "    return markdown_table\n",
    "\n",
    "\n",
    "data.loc[:,'core_dataset_name'] = data['dataset_name'].apply(extract_core_dataset_name)\n",
    "\n",
    "data.loc[:,'noise_ratio'] = data['dataset_name'].apply(extract_noise_ratio)\n",
    "\n",
    "data = data[['method','core_dataset_name','noise_ratio','test_loss_mean','test_loss_std']]\n",
    "data.columns = ['Method','Dataset','Noise Ratio','Test Loss Mean','Test Loss Std']\n",
    "\n",
    "# Create a latex table where each row is a method and each column is a dataset\n",
    "# For each dataset, have a separate subcolumn for each noise ratio\n",
    "# Each value should show the mean test loss and the standard deviation a a subscript in parentheses\n",
    "\n",
    "datasets = data['Dataset'].unique()\n",
    "methods = data['Method'].unique()\n",
    "noise_ratios = data['Noise Ratio'].unique()\n",
    "\n",
    "# Construct two-level column names\n",
    "column_names = []\n",
    "for dataset in datasets:\n",
    "    for noise_ratio in noise_ratios:\n",
    "        column_names.append((dataset,noise_ratio))\n",
    "\n",
    "latex_table = pd.DataFrame(index=methods,columns=pd.MultiIndex.from_tuples(column_names))\n",
    "\n",
    "for dataset in datasets:\n",
    "    for method in methods:\n",
    "        for noise_ratio in noise_ratios:\n",
    "            mask = (data['Dataset']==dataset) & (data['Method']==method) & (data['Noise Ratio']==noise_ratio)\n",
    "            if mask.sum() > 0:\n",
    "                mean = data.loc[mask,'Test Loss Mean'].values[0]\n",
    "                std = data.loc[mask,'Test Loss Std'].values[0]\n",
    "                formatted_noise = f\"{std:.3f}\".lstrip('0')\n",
    "                latex_table.loc[method,(dataset,noise_ratio)] = fr\"${mean:.3f}_\"+\"{(\"+formatted_noise+r\")}$\"\n",
    "\n",
    "\n",
    "\n",
    "dataset_dict = {\n",
    "    'simple':'Logistic Growth',\n",
    "    'general':'General ODE',\n",
    "    'tacrolimus':'Pharmacokinetic',\n",
    "    'mackey':'Mackey-Glass',\n",
    "    'integral':'Integro-DE',\n",
    "    'duffing':'Duffing',\n",
    "    'tumor-real':'Tumor growth (real)',\n",
    "    'tacrolimus-real':'Drug concentration (real)',\n",
    "}\n",
    "\n",
    "method_dict = {\n",
    "    'NeuralODE':'Neural ODE',\n",
    "    'NeuralLaplace':'Neural Laplace',\n",
    "    'DeepONet':'DeepONet',\n",
    "    'SemanticODE-default':'Semantic ODE',\n",
    "    'WeakSINDy-5':'WSINDy-5',\n",
    "    'SINDy-0':'SINDy',\n",
    "    'WeakSINDy-0':'WSINDy'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">simple</th>\n",
       "      <th colspan=\"2\" halign=\"left\">tacrolimus</th>\n",
       "      <th colspan=\"2\" halign=\"left\">mackey</th>\n",
       "      <th colspan=\"2\" halign=\"left\">general</th>\n",
       "      <th colspan=\"2\" halign=\"left\">integral</th>\n",
       "      <th colspan=\"2\" halign=\"left\">tumor-real</th>\n",
       "      <th colspan=\"2\" halign=\"left\">duffing</th>\n",
       "      <th colspan=\"2\" halign=\"left\">tacrolimus-real</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.20</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.20</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.20</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.20</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.20</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.20</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.20</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SINDy-5</th>\n",
       "      <td>$0.012_{(.002)}$</td>\n",
       "      <td>$0.222_{(.004)}$</td>\n",
       "      <td>$0.093_{(.004)}$</td>\n",
       "      <td>$0.230_{(.014)}$</td>\n",
       "      <td>$0.238_{(.023)}$</td>\n",
       "      <td>$0.248_{(.025)}$</td>\n",
       "      <td>$0.053_{(.012)}$</td>\n",
       "      <td>$0.103_{(.010)}$</td>\n",
       "      <td>$0.431_{(.051)}$</td>\n",
       "      <td>$0.268_{(.019)}$</td>\n",
       "      <td>$0.243_{(.019)}$</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$0.278_{(.032)}$</td>\n",
       "      <td>$0.389_{(.059)}$</td>\n",
       "      <td>$0.286_{(.021)}$</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WeakSINDy-5</th>\n",
       "      <td>$0.010_{(.000)}$</td>\n",
       "      <td>$0.222_{(.009)}$</td>\n",
       "      <td>$0.211_{(.009)}$</td>\n",
       "      <td>$0.415_{(.299)}$</td>\n",
       "      <td>$0.272_{(.032)}$</td>\n",
       "      <td>$0.300_{(.061)}$</td>\n",
       "      <td>$0.066_{(.009)}$</td>\n",
       "      <td>$0.102_{(.008)}$</td>\n",
       "      <td>$0.160_{(.066)}$</td>\n",
       "      <td>$0.452_{(.365)}$</td>\n",
       "      <td>$0.237_{(.015)}$</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$0.262_{(.033)}$</td>\n",
       "      <td>$0.361_{(.072)}$</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SINDy-0</th>\n",
       "      <td>$0.012_{(.001)}$</td>\n",
       "      <td>$0.218_{(.011)}$</td>\n",
       "      <td>$0.020_{(.001)}$</td>\n",
       "      <td>$0.209_{(.010)}$</td>\n",
       "      <td>$0.252_{(.026)}$</td>\n",
       "      <td>$0.257_{(.028)}$</td>\n",
       "      <td>$0.068_{(.013)}$</td>\n",
       "      <td>$0.115_{(.012)}$</td>\n",
       "      <td>$0.318_{(.172)}$</td>\n",
       "      <td>$0.248_{(.016)}$</td>\n",
       "      <td>$0.249_{(.029)}$</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$0.284_{(.026)}$</td>\n",
       "      <td>$0.386_{(.022)}$</td>\n",
       "      <td>$0.286_{(.014)}$</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WeakSINDy-0</th>\n",
       "      <td>$0.010_{(.001)}$</td>\n",
       "      <td>$0.217_{(.016)}$</td>\n",
       "      <td>$0.038_{(.006)}$</td>\n",
       "      <td>$0.219_{(.016)}$</td>\n",
       "      <td>$0.200_{(.035)}$</td>\n",
       "      <td>$0.207_{(.031)}$</td>\n",
       "      <td>$0.062_{(.009)}$</td>\n",
       "      <td>$0.112_{(.009)}$</td>\n",
       "      <td>$0.152_{(.086)}$</td>\n",
       "      <td>$0.300_{(.082)}$</td>\n",
       "      <td>$0.236_{(.016)}$</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$0.263_{(.027)}$</td>\n",
       "      <td>$0.339_{(.037)}$</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PySR-20</th>\n",
       "      <td>$0.012_{(.002)}$</td>\n",
       "      <td>$0.224_{(.007)}$</td>\n",
       "      <td>$0.053_{(.015)}$</td>\n",
       "      <td>$0.242_{(.039)}$</td>\n",
       "      <td>$0.261_{(.021)}$</td>\n",
       "      <td>$0.288_{(.031)}$</td>\n",
       "      <td>$0.078_{(.029)}$</td>\n",
       "      <td>$0.119_{(.029)}$</td>\n",
       "      <td>$0.027_{(.011)}$</td>\n",
       "      <td>$0.393_{(.144)}$</td>\n",
       "      <td>$0.536_{(.346)}$</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$0.312_{(.049)}$</td>\n",
       "      <td>$0.396_{(.020)}$</td>\n",
       "      <td>$0.257_{(.022)}$</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SemanticODE-default</th>\n",
       "      <td>$0.015_{(.005)}$</td>\n",
       "      <td>$0.200_{(.009)}$</td>\n",
       "      <td>$0.023_{(.014)}$</td>\n",
       "      <td>$0.211_{(.015)}$</td>\n",
       "      <td>$0.037_{(.003)}$</td>\n",
       "      <td>$0.075_{(.003)}$</td>\n",
       "      <td>$0.015_{(.001)}$</td>\n",
       "      <td>$0.068_{(.002)}$</td>\n",
       "      <td>$0.025_{(.003)}$</td>\n",
       "      <td>$0.203_{(.007)}$</td>\n",
       "      <td>$0.234_{(.019)}$</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$0.090_{(.012)}$</td>\n",
       "      <td>$0.251_{(.027)}$</td>\n",
       "      <td>$0.264_{(.021)}$</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralODE</th>\n",
       "      <td>$0.023_{(.004)}$</td>\n",
       "      <td>$0.197_{(.005)}$</td>\n",
       "      <td>$0.036_{(.008)}$</td>\n",
       "      <td>$0.203_{(.007)}$</td>\n",
       "      <td>$0.177_{(.010)}$</td>\n",
       "      <td>$0.194_{(.010)}$</td>\n",
       "      <td>$0.029_{(.005)}$</td>\n",
       "      <td>$0.075_{(.006)}$</td>\n",
       "      <td>$0.073_{(.007)}$</td>\n",
       "      <td>$0.215_{(.009)}$</td>\n",
       "      <td>$0.228_{(.018)}$</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$0.212_{(.018)}$</td>\n",
       "      <td>$0.291_{(.021)}$</td>\n",
       "      <td>$0.263_{(.032)}$</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SemanticODE-tumor</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$0.229_{(.019)}$</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SemanticODE-pharma</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$0.243_{(.015)}$</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepONet</th>\n",
       "      <td>$0.184_{(.040)}$</td>\n",
       "      <td>$0.306_{(.023)}$</td>\n",
       "      <td>$0.058_{(.010)}$</td>\n",
       "      <td>$0.212_{(.005)}$</td>\n",
       "      <td>$0.107_{(.014)}$</td>\n",
       "      <td>$0.132_{(.012)}$</td>\n",
       "      <td>$0.160_{(.033)}$</td>\n",
       "      <td>$0.195_{(.027)}$</td>\n",
       "      <td>$0.100_{(.015)}$</td>\n",
       "      <td>$0.230_{(.014)}$</td>\n",
       "      <td>$0.242_{(.016)}$</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$0.429_{(.084)}$</td>\n",
       "      <td>$0.528_{(.066)}$</td>\n",
       "      <td>$0.265_{(.020)}$</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralLaplace</th>\n",
       "      <td>$0.126_{(.036)}$</td>\n",
       "      <td>$0.230_{(.017)}$</td>\n",
       "      <td>$0.100_{(.022)}$</td>\n",
       "      <td>$0.229_{(.013)}$</td>\n",
       "      <td>$0.057_{(.006)}$</td>\n",
       "      <td>$0.094_{(.009)}$</td>\n",
       "      <td>$0.108_{(.030)}$</td>\n",
       "      <td>$0.138_{(.023)}$</td>\n",
       "      <td>$0.075_{(.044)}$</td>\n",
       "      <td>$0.249_{(.014)}$</td>\n",
       "      <td>$0.243_{(.029)}$</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$0.176_{(.032)}$</td>\n",
       "      <td>$0.299_{(.017)}$</td>\n",
       "      <td>$0.302_{(.022)}$</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               simple                          tacrolimus  \\\n",
       "                                 0.01              0.20              0.01   \n",
       "SINDy-5              $0.012_{(.002)}$  $0.222_{(.004)}$  $0.093_{(.004)}$   \n",
       "WeakSINDy-5          $0.010_{(.000)}$  $0.222_{(.009)}$  $0.211_{(.009)}$   \n",
       "SINDy-0              $0.012_{(.001)}$  $0.218_{(.011)}$  $0.020_{(.001)}$   \n",
       "WeakSINDy-0          $0.010_{(.001)}$  $0.217_{(.016)}$  $0.038_{(.006)}$   \n",
       "PySR-20              $0.012_{(.002)}$  $0.224_{(.007)}$  $0.053_{(.015)}$   \n",
       "SemanticODE-default  $0.015_{(.005)}$  $0.200_{(.009)}$  $0.023_{(.014)}$   \n",
       "NeuralODE            $0.023_{(.004)}$  $0.197_{(.005)}$  $0.036_{(.008)}$   \n",
       "SemanticODE-tumor                 NaN               NaN               NaN   \n",
       "SemanticODE-pharma                NaN               NaN               NaN   \n",
       "DeepONet             $0.184_{(.040)}$  $0.306_{(.023)}$  $0.058_{(.010)}$   \n",
       "NeuralLaplace        $0.126_{(.036)}$  $0.230_{(.017)}$  $0.100_{(.022)}$   \n",
       "\n",
       "                                                 mackey                    \\\n",
       "                                 0.20              0.01              0.20   \n",
       "SINDy-5              $0.230_{(.014)}$  $0.238_{(.023)}$  $0.248_{(.025)}$   \n",
       "WeakSINDy-5          $0.415_{(.299)}$  $0.272_{(.032)}$  $0.300_{(.061)}$   \n",
       "SINDy-0              $0.209_{(.010)}$  $0.252_{(.026)}$  $0.257_{(.028)}$   \n",
       "WeakSINDy-0          $0.219_{(.016)}$  $0.200_{(.035)}$  $0.207_{(.031)}$   \n",
       "PySR-20              $0.242_{(.039)}$  $0.261_{(.021)}$  $0.288_{(.031)}$   \n",
       "SemanticODE-default  $0.211_{(.015)}$  $0.037_{(.003)}$  $0.075_{(.003)}$   \n",
       "NeuralODE            $0.203_{(.007)}$  $0.177_{(.010)}$  $0.194_{(.010)}$   \n",
       "SemanticODE-tumor                 NaN               NaN               NaN   \n",
       "SemanticODE-pharma                NaN               NaN               NaN   \n",
       "DeepONet             $0.212_{(.005)}$  $0.107_{(.014)}$  $0.132_{(.012)}$   \n",
       "NeuralLaplace        $0.229_{(.013)}$  $0.057_{(.006)}$  $0.094_{(.009)}$   \n",
       "\n",
       "                              general                            integral  \\\n",
       "                                 0.01              0.20              0.01   \n",
       "SINDy-5              $0.053_{(.012)}$  $0.103_{(.010)}$  $0.431_{(.051)}$   \n",
       "WeakSINDy-5          $0.066_{(.009)}$  $0.102_{(.008)}$  $0.160_{(.066)}$   \n",
       "SINDy-0              $0.068_{(.013)}$  $0.115_{(.012)}$  $0.318_{(.172)}$   \n",
       "WeakSINDy-0          $0.062_{(.009)}$  $0.112_{(.009)}$  $0.152_{(.086)}$   \n",
       "PySR-20              $0.078_{(.029)}$  $0.119_{(.029)}$  $0.027_{(.011)}$   \n",
       "SemanticODE-default  $0.015_{(.001)}$  $0.068_{(.002)}$  $0.025_{(.003)}$   \n",
       "NeuralODE            $0.029_{(.005)}$  $0.075_{(.006)}$  $0.073_{(.007)}$   \n",
       "SemanticODE-tumor                 NaN               NaN               NaN   \n",
       "SemanticODE-pharma                NaN               NaN               NaN   \n",
       "DeepONet             $0.160_{(.033)}$  $0.195_{(.027)}$  $0.100_{(.015)}$   \n",
       "NeuralLaplace        $0.108_{(.030)}$  $0.138_{(.023)}$  $0.075_{(.044)}$   \n",
       "\n",
       "                                             tumor-real       \\\n",
       "                                 0.20              0.01 0.20   \n",
       "SINDy-5              $0.268_{(.019)}$  $0.243_{(.019)}$  NaN   \n",
       "WeakSINDy-5          $0.452_{(.365)}$  $0.237_{(.015)}$  NaN   \n",
       "SINDy-0              $0.248_{(.016)}$  $0.249_{(.029)}$  NaN   \n",
       "WeakSINDy-0          $0.300_{(.082)}$  $0.236_{(.016)}$  NaN   \n",
       "PySR-20              $0.393_{(.144)}$  $0.536_{(.346)}$  NaN   \n",
       "SemanticODE-default  $0.203_{(.007)}$  $0.234_{(.019)}$  NaN   \n",
       "NeuralODE            $0.215_{(.009)}$  $0.228_{(.018)}$  NaN   \n",
       "SemanticODE-tumor                 NaN  $0.229_{(.019)}$  NaN   \n",
       "SemanticODE-pharma                NaN               NaN  NaN   \n",
       "DeepONet             $0.230_{(.014)}$  $0.242_{(.016)}$  NaN   \n",
       "NeuralLaplace        $0.249_{(.014)}$  $0.243_{(.029)}$  NaN   \n",
       "\n",
       "                              duffing                     tacrolimus-real       \n",
       "                                 0.01              0.20              0.01 0.20  \n",
       "SINDy-5              $0.278_{(.032)}$  $0.389_{(.059)}$  $0.286_{(.021)}$  NaN  \n",
       "WeakSINDy-5          $0.262_{(.033)}$  $0.361_{(.072)}$               NaN  NaN  \n",
       "SINDy-0              $0.284_{(.026)}$  $0.386_{(.022)}$  $0.286_{(.014)}$  NaN  \n",
       "WeakSINDy-0          $0.263_{(.027)}$  $0.339_{(.037)}$               NaN  NaN  \n",
       "PySR-20              $0.312_{(.049)}$  $0.396_{(.020)}$  $0.257_{(.022)}$  NaN  \n",
       "SemanticODE-default  $0.090_{(.012)}$  $0.251_{(.027)}$  $0.264_{(.021)}$  NaN  \n",
       "NeuralODE            $0.212_{(.018)}$  $0.291_{(.021)}$  $0.263_{(.032)}$  NaN  \n",
       "SemanticODE-tumor                 NaN               NaN               NaN  NaN  \n",
       "SemanticODE-pharma                NaN               NaN  $0.243_{(.015)}$  NaN  \n",
       "DeepONet             $0.429_{(.084)}$  $0.528_{(.066)}$  $0.265_{(.020)}$  NaN  \n",
       "NeuralLaplace        $0.176_{(.032)}$  $0.299_{(.017)}$  $0.302_{(.022)}$  NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latex_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_noise_level(df):\n",
    "    df.columns = pd.MultiIndex.from_tuples([(col[0],\"low\" if col[1]==0.01 else \"high\") for col in df.columns])\n",
    "    columns = df.columns.values\n",
    "    df.columns = [col[0] for col in columns]\n",
    "    second_level_values = [col[1] for col in columns]\n",
    "    df.loc['Noise Level'] = second_level_values\n",
    "    df = df.reindex(['Noise Level'] + [col for col in df.index if col != 'Noise Level'])\n",
    "    return df\n",
    "\n",
    "\n",
    "datasets_in_order = ['simple','general','tacrolimus','mackey','integral']\n",
    "methods_in_order = ['SINDy-5','WeakSINDy-5','PySR-20','SINDy-0','WeakSINDy-0','NeuralODE','NeuralLaplace','DeepONet','SemanticODE-default']\n",
    "\n",
    "black_box_table = latex_table.loc[methods_in_order,datasets_in_order]\n",
    "black_box_table = black_box_table.rename(index=method_dict)\n",
    "black_box_table = black_box_table.rename(columns=dataset_dict)\n",
    "\n",
    "# Save as a latex table\n",
    "with open('output/Main Table (Tab 3).tex', 'w') as f:\n",
    "    f.write(black_box_table.to_latex(escape=False))\n",
    "\n",
    "black_box_table = flatten_noise_level(black_box_table)\n",
    "\n",
    "with open('output/Main Table (Tab 3).md', 'w') as f:\n",
    "    f.write(dataframe_to_markdown(black_box_table))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_in_order = ['SINDy-5','WeakSINDy-5','PySR-20','SINDy-0','WeakSINDy-0','NeuralODE','NeuralLaplace','DeepONet','SemanticODE-default']\n",
    "\n",
    "duffing_table = latex_table.loc[methods_in_order,['duffing']]\n",
    "\n",
    "duffing_table = duffing_table.rename(index=method_dict)\n",
    "duffing_table = duffing_table.rename(columns=dataset_dict)\n",
    "\n",
    "# Save as a latex table\n",
    "with open('output/Duffing (Tab 6).tex', 'w') as f:\n",
    "    f.write(duffing_table.to_latex(escape=False))\n",
    "\n",
    "duffing_table = flatten_noise_level(duffing_table)\n",
    "\n",
    "with open('output/Duffing (Tab 6).md', 'w') as f:\n",
    "    f.write(dataframe_to_markdown(duffing_table))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_table = methods_in_order = ['SINDy-5','WeakSINDy-5','PySR-20','SINDy-0','WeakSINDy-0','NeuralODE','NeuralLaplace','DeepONet','SemanticODE-default','SemanticODE-tumor','SemanticODE-pharma']\n",
    "\n",
    "real_data_table = latex_table.loc[methods_in_order,['tumor-real','tacrolimus-real']]\n",
    "\n",
    "real_data_table = real_data_table.rename(index=method_dict)\n",
    "real_data_table = real_data_table.rename(columns=dataset_dict)\n",
    "real_data_table = flatten_noise_level(real_data_table)\n",
    "\n",
    "real_data_table = real_data_table.iloc[:,[0,2]]\n",
    "\n",
    "with open('output/Real data (Tab 7).md', 'w') as f:\n",
    "    f.write(dataframe_to_markdown(real_data_table))\n",
    "\n",
    "# Save as a latex table\n",
    "with open('output/Real data (Tab 7).tex', 'w') as f:\n",
    "    f.write(real_data_table.to_latex(escape=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sketch-odes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
